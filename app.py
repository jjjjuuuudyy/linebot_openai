from flask import Flask, request, abort

from linebot import (
    LineBotApi, WebhookHandler
)
from linebot.exceptions import (
    InvalidSignatureError
)
from linebot.models import *

#======pythonçš„å‡½æ•¸åº«==========
import tempfile, os
import datetime
import openai
import time
import traceback
#======pythonçš„å‡½æ•¸åº«==========

app = Flask(__name__)
static_tmp_path = os.path.join(os.path.dirname(__file__), 'static', 'tmp')
# Channel Access Token
line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
# Channel Secret
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))
# OPENAI API Keyåˆå§‹åŒ–è¨­å®š
openai.api_key = os.getenv("GITHUB_TOKEN")
openai.api_base = "https://models.github.ai/inference"


def GPT_response(text):
    prompt = f""" 
        ä½ æ˜¯ä¸€å€‹å‹å–„ä¸”ç²¾ç°¡çš„åŠ©ç†ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›è¦†ï¼Œèªæ°£è‡ªç„¶æº«æš–ã€‚
        é©åº¦åŠ å…¥ Emoji å¢æ·»è¦ªåˆ‡æ„Ÿã€‚å›ç­”æ‡‰ç°¡çŸ­ã€æœ‰é‡é»ï¼Œé¿å…å†—é•·ã€‚
        ä¸è¦å‡ºç¾ Markdown æˆ–æ›è¡Œç¬¦è™Ÿã€‚
    """
    # æ¥æ”¶å›æ‡‰
    # response = openai.Completion.create(model="gpt-3.5-turbo-instruct", prompt=text, temperature=0.5, max_tokens=500)
    response = openai.ChatCompletion.create(
        model="openai/gpt-4o",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": text},
        ]
    )
    print(response)
    # é‡çµ„å›æ‡‰
    # answer = response['choices'][0]['text'].replace('ã€‚','')
    answer = response["choices"][0]["message"]["content"]
    return answer


# ç›£è½æ‰€æœ‰ä¾†è‡ª /callback çš„ Post Request
@app.route("/callback", methods=['POST'])
def callback():
    # get X-Line-Signature header value
    signature = request.headers['X-Line-Signature']
    # get request body as text
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)
    # handle webhook body
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'


# è™•ç†è¨Šæ¯
# @handler.add(MessageEvent, message=TextMessage)
# def handle_message(event):
#     msg = event.message.text
#     try:
#         GPT_answer = GPT_response(msg)
#         print(GPT_answer)
#         line_bot_api.reply_message(event.reply_token, TextSendMessage(GPT_answer))
#     except:
#         print(traceback.format_exc())
#         line_bot_api.reply_message(event.reply_token, TextSendMessage('ä½ æ‰€ä½¿ç”¨çš„OPENAI API keyé¡åº¦å¯èƒ½å·²ç¶“è¶…éï¼Œè«‹æ–¼å¾Œå°Logå…§ç¢ºèªéŒ¯èª¤è¨Šæ¯'))
        

@handler.add(PostbackEvent)
def handle_message(event):
    print(event.postback.data)


@handler.add(MemberJoinedEvent)
def welcome(event):
    uid = event.joined.members[0].user_id
    gid = event.source.group_id
    profile = line_bot_api.get_group_member_profile(gid, uid)
    name = profile.display_name
    message = TextSendMessage(text=f'{name}æ­¡è¿åŠ å…¥')
    line_bot_api.reply_message(event.reply_token, message)
        
        
import os
if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)


#========MQTTç›¸é—œ==========
from mqtt import send_mqtt

MQTT_TOPIC_LED = "judy0528/class304/led"
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    msg = event.message.text

    try:
        if msg == "é–‹å•ŸLED":
            send_mqtt(MQTT_TOPIC_LED, "ON")
            line_bot_api.reply_message(event.reply_token, TextSendMessage("ğŸŸ¢ å·²é–‹å•Ÿ LED"))
            return
        elif msg == "é—œé–‰LED":
            send_mqtt(MQTT_TOPIC_LED, "OFF")
            line_bot_api.reply_message(event.reply_token, TextSendMessage("âšª å·²é—œé–‰ LED"))
            return

        # å…¶ä»–è¨Šæ¯
        line_bot_api.reply_message(event.reply_token, TextSendMessage("æœªæˆæ¬Šçš„æŒ‡ä»¤"))

    except Exception as e:
        print(traceback.format_exc())
        line_bot_api.reply_message(event.reply_token, TextSendMessage("ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"))
#========MQTTç›¸é—œ==========